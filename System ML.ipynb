{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting https://github.com/IBM/coursera/blob/master/systemml-1.3.0-SNAPSHOT-python.tar.gz?raw=true\n\u001b[?25l  Downloading https://github.com/IBM/coursera/blob/master/systemml-1.3.0-SNAPSHOT-python.tar.gz?raw=true (9.9MB)\n\u001b[K    100% |################################| 9.9MB 1.1MB/s eta 0:00:01\n\u001b[?25hCollecting numpy>=1.8.2 (from systemml==1.3.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n\u001b[K    100% |################################| 17.3MB 1.0MB/s eta 0:00:01\n\u001b[?25hCollecting scipy>=0.15.1 (from systemml==1.3.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n\u001b[K    100% |################################| 25.2MB 770kB/s eta 0:00:01\n\u001b[?25hCollecting pandas (from systemml==1.3.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n\u001b[K    100% |################################| 10.1MB 1.5MB/s eta 0:00:01\n\u001b[?25hCollecting scikit-learn (from systemml==1.3.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n\u001b[K    100% |################################| 6.7MB 1.9MB/s eta 0:00:01\n\u001b[?25hCollecting Pillow>=2.0.0 (from systemml==1.3.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n\u001b[K    100% |################################| 2.0MB 2.9MB/s eta 0:00:01\n\u001b[?25hCollecting python-dateutil>=2.5.0 (from pandas->systemml==1.3.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n\u001b[K    100% |################################| 235kB 3.9MB/s eta 0:00:01\n\u001b[?25hCollecting pytz>=2011k (from pandas->systemml==1.3.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n\u001b[K    100% |################################| 512kB 3.8MB/s eta 0:00:01\n\u001b[?25hCollecting joblib>=0.11 (from scikit-learn->systemml==1.3.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n\u001b[K    100% |################################| 286kB 4.0MB/s eta 0:00:01\n\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.5.0->pandas->systemml==1.3.0)\n  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\nBuilding wheels for collected packages: systemml\n  Building wheel for systemml (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/aa/bf/28/4344dd13abd8b9b6cbd4032baf4b851873d2e2288a65631fd2\nSuccessfully built systemml\n\u001b[31mtensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\nInstalling collected packages: numpy, scipy, six, python-dateutil, pytz, pandas, joblib, scikit-learn, Pillow, systemml\nSuccessfully installed Pillow-6.0.0 joblib-0.13.2 numpy-1.16.4 pandas-0.24.2 python-dateutil-2.8.0 pytz-2019.1 scikit-learn-0.21.2 scipy-1.3.0 six-1.12.0 systemml-1.3.0\n"
                }
            ], 
            "source": "!pip install https://github.com/IBM/coursera/blob/master/systemml-1.3.0-SNAPSHOT-python.tar.gz?raw=true"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ln -s -f ~/user-libs/python3/systemml/systemml-java/systemml-1.3.0-SNAPSHOT-extra.jar ~/user-libs/spark2/systemml-1.3.0-SNAPSHOT-extra.jar\n!ln -s -f ~/user-libs/python3/systemml/systemml-java/systemml-1.3.0-SNAPSHOT.jar ~/user-libs/spark2/systemml-1.3.0-SNAPSHOT.jar"
        }, 
        {
            "source": "# Restart the kernal after running first 2 blocks", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190610212224-0001\nKERNEL_ID = ac1ff81e-3b5d-4ce4-80d0-d2e582a72cc3\n"
                }
            ], 
            "source": "from systemml import dml, MLContext\nimport numpy as np"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ml = MLContext(spark)"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "script = \"\"\"\nc = sum(a %*% t(b))\n\"\"\""
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SystemML Statistics:\nTotal execution time:\t\t0.001 sec.\nNumber of executed Spark inst:\t2.\n\n\n"
                }, 
                {
                    "execution_count": 6, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "32.0"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "a = np.array([[1, 2, 3]])\nb = np.array([[4, 5, 6]])\nprog = dml(script).input('a', a).input('b', b).output('c')\nc = ml.execute(prog).get('c')\nc"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Name: systemml\r\nVersion: 1.3.0\r\nSummary: Apache SystemML is a distributed and declarative machine learning platform.\r\nHome-page: http://systemml.apache.org/\r\nAuthor: Apache SystemML\r\nAuthor-email: dev@systemml.apache.org\r\nLicense: Apache 2.0\r\nLocation: /home/spark/shared/user-libs/python3\r\nRequires: Pillow, scipy, numpy, scikit-learn, pandas\r\nRequired-by: \r\n"
                }
            ], 
            "source": "!pip show systemml"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 8, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "'2.3.3'"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "sc.version"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Archiver-Version: Plexus Archiver\nArtifact-Id: systemml\nBuild-Jdk: 1.8.0_181\nBuild-Time: 2019-03-19 23:17:12 UTC\nBuilt-By: npansar\nCreated-By: Apache Maven 3.5.4\nGroup-Id: org.apache.systemml\nMain-Class: org.apache.sysml.api.DMLScript\nManifest-Version: 1.0\nMinimum-Recommended-Spark-Version: 2.3.0\nVersion: 1.3.0-SNAPSHOT\n\n"
                }
            ], 
            "source": "print(ml.info())"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ml = MLContext(sc)"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Archiver-Version: Plexus Archiver\nArtifact-Id: systemml\nBuild-Jdk: 1.8.0_181\nBuild-Time: 2019-03-19 23:17:12 UTC\nBuilt-By: npansar\nCreated-By: Apache Maven 3.5.4\nGroup-Id: org.apache.systemml\nMain-Class: org.apache.sysml.api.DMLScript\nManifest-Version: 1.0\nMinimum-Recommended-Spark-Version: 2.3.0\nVersion: 1.3.0-SNAPSHOT\n\n"
                }
            ], 
            "source": "print(ml.info())"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Hello World\nSystemML Statistics:\nTotal execution time:\t\t0.001 sec.\nNumber of executed Spark inst:\t0.\n\n\n"
                }, 
                {
                    "execution_count": 13, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "MLResults"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "script = dml(\"\"\"\nprint('Hello World');\n\"\"\")\nml.execute(script)"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SystemML Statistics:\nTotal execution time:\t\t0.000 sec.\nNumber of executed Spark inst:\t0.\n\n\nHello World\n"
                }
            ], 
            "source": "script = dml(\"\"\"\ns = 'Hello World'\n\"\"\").output(\"s\")\n\nhello_world_str = ml.execute(script).get(\"s\")\n\nprint(hello_world_str)"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import sys, os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets\nplt.switch_backend('agg')"
        }, 
        {
            "source": "# Example 1: Matrix Multiplication\n\n### SystemML script to generate a random matrix, perform matrix multiplication, and compute the sum of the output", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SystemML Statistics:\nTotal execution time:\t\t43.795 sec.\nNumber of executed Spark inst:\t2.\n\n\n62600179263.402405\n"
                }
            ], 
            "source": "script = \"\"\"\n    X = rand(rows=$nr, cols=1000, sparsity=0.5)\n    A = t(X) %*% X\n    s = sum(A)\n\"\"\"\nprog = dml(script).input('$nr', 1e6).output('s')\ns = ml.execute(prog).get('s')\nprint(s)"
        }, 
        {
            "source": "## Load diabetes dataset from scikit-learn", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline"
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "diabetes = datasets.load_diabetes()\ndiabetes_X = diabetes.data[:, np.newaxis, 2]\ndiabetes_X_train = diabetes_X[:-20]\ndiabetes_X_test = diabetes_X[-20:]\ndiabetes_y_train = np.matrix(diabetes.target[:-20]).T\ndiabetes_y_test = np.matrix(diabetes.target[-20:]).T"
        }, 
        {
            "execution_count": 33, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "script = \"\"\"\n    # add constant feature to X to model intercept\n    ones = matrix(1, rows=nrow(X), cols=1)\n    X = cbind(X, ones)\n    A = t(X) %*% X\n    b = t(X) %*% y\n    w = solve(A, b)\n    bias = as.scalar(w[nrow(w), 1])\n    w = w[1:nrow(w) - 1,]\n\"\"\""
        }, 
        {
            "execution_count": 34, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SystemML Statistics:\nTotal execution time:\t\t0.043 sec.\nNumber of executed Spark inst:\t2.\n\n\n"
                }
            ], 
            "source": "prog = dml(script).input(X=diabetes_X_train, y=diabetes_y_train).output('w', 'bias')\nw, bias = ml.execute(prog).get('w', 'bias')\nw = w.toNumPy()"
        }, 
        {
            "execution_count": 36, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(array([[938.23786125]]), 152.91886182616167)\n"
                }
            ], 
            "source": "print((w, bias)) #w = slope, bias = intercept"
        }, 
        {
            "source": "# Batch gradient decent", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 37, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "script = \"\"\"\n    ones = matrix(1, rows = nrow(X), cols = 1)\n    X = cbind(X, ones)\n    max_iter = 100\n    w = matrix(0, rows=ncol(X), cols = 1)\n    for(i in 1:max_iter){\n        XtX = t(X) %*% X\n        dw = XtX %*% w - t(X) %*% y\n        alpha = (t(dw) %*% dw) / (t(dw) %*% XtX %*% dw)\n        w = w - dw * alpha\n    }\n    bias = as.scalar(w[nrow(w),1])\n    w = w[1:nrow(w) -1,]\n\"\"\""
        }, 
        {
            "execution_count": 38, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SystemML Statistics:\nTotal execution time:\t\t0.140 sec.\nNumber of executed Spark inst:\t2.\n\n\n"
                }
            ], 
            "source": "prog = dml(script).input(X=diabetes_X_train, y=diabetes_y_train).output('w').output('bias')\nw, bias = ml.execute(prog).get('w', 'bias')\nw = w.toNumPy()"
        }, 
        {
            "execution_count": 39, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "152.9188618261617\n[[938.23786125]]\n"
                }
            ], 
            "source": "print(bias)\nprint(w)"
        }, 
        {
            "source": "# Conjugate Gradient", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 40, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "script = \"\"\"\n    X = cbind(X, matrix(1, rows=nrow(X), cols=1))\n    m = ncol(X);\n    i = 1;\n    max_iter = 20;\n    w = matrix(0, rows = m, cols = 1); # initialize weights to 0\n    dw = -t(X) %*% y;\n    p = -dw;\n    norm_r2 = sum(dw^2);\n    for(i in 1:max_iter){\n        q = t(X) %*% (X %*% p)\n        alpha = norm_r2 / sum(p * q);\n        w = w + alpha * p;\n        dw = dw + alpha * q;\n        old_norm_r2 = norm_r2;\n        norm_r2 = sum(dw^2);\n        p = -dw + (norm_r2 / old_norm_r2) * p;\n        i = i + 1;\n    }\n    bias = as.scalar(w[nrow(w),1])\n    w = w[1:nrow(w) -1,]\n\"\"\""
        }, 
        {
            "execution_count": 41, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SystemML Statistics:\nTotal execution time:\t\t0.016 sec.\nNumber of executed Spark inst:\t2.\n\n\n"
                }
            ], 
            "source": "prog = dml(script).input(X=diabetes_X_train, y=diabetes_y_train).output('w').output('bias')\nw, bias = ml.execute(prog).get('w', 'bias')\nw = w.toNumPy()"
        }, 
        {
            "execution_count": 42, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "152.91886182616167\n[[938.23786125]]\n"
                }
            ], 
            "source": "print(bias)\nprint(w)"
        }, 
        {
            "source": "# Using pre built scripts", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 44, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "BEGIN LINEAR REGRESSION SCRIPT\nReading X and Y...\nCalling the Direct Solver...\nComputing the statistics...\nAVG_TOT_Y,153.36255924170615\nSTDEV_TOT_Y,77.21853383600028\nAVG_RES_Y,3.633533705616816E-14\nSTDEV_RES_Y,63.038506337610244\nDISPERSION,3973.853281276927\nR2,0.3351312506863875\nADJUSTED_R2,0.33354822985468835\nR2_NOBIAS,0.3351312506863875\nADJUSTED_R2_NOBIAS,0.33354822985468835\nWriting the output matrix...\nEND LINEAR REGRESSION SCRIPT\nSystemML Statistics:\nTotal execution time:\t\t0.010 sec.\nNumber of executed Spark inst:\t2.\n\n\n[[938.23687951]\n [152.91886229]]\n"
                }
            ], 
            "source": "from systemml import dmlFromResource\nprog = dmlFromResource('scripts/algorithms/LinearRegDS.dml').input(X=diabetes_X_train, y=diabetes_y_train).input('$icpt', 1.0).output('beta_out')\nw = ml.execute(prog).get('beta_out')\nw = w.toNumPy()\nbias = w[1]\nprint(w)"
        }, 
        {
            "source": "# Using scikit-learn", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 45, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.sql import SQLContext\nfrom systemml.mllearn import LinearRegression\nsqlCtx = SQLContext(sc)"
        }, 
        {
            "execution_count": 46, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "BEGIN LINEAR REGRESSION SCRIPT\nReading X and Y...\nRunning the CG algorithm...\n||r|| initial value = 64725.64237405237,  target value = 0.06472564237405237\nIteration 1:  ||r|| / ||r init|| = 0.013822097283108787\nIteration 2:  ||r|| / ||r init|| = 5.369915930350396E-14\nThe CG algorithm is done.\nComputing the statistics...\nAVG_TOT_Y,153.36255924170615\nSTDEV_TOT_Y,77.21853383600028\nAVG_RES_Y,-8.227243004822623E-12\nSTDEV_RES_Y,63.03850633759284\nDISPERSION,3973.853281274733\nR2,0.33513125068675453\nADJUSTED_R2,0.3335482298550564\nR2_NOBIAS,0.33513125068675453\nADJUSTED_R2_NOBIAS,0.3335482298550564\nWriting the output matrix...\nEND LINEAR REGRESSION SCRIPT\nSystemML Statistics:\nTotal execution time:\t\t0.006 sec.\nNumber of executed Spark inst:\t2.\n\n\n"
                }, 
                {
                    "execution_count": 46, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "lr"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "regr = LinearRegression(sqlCtx)\nregr.fit(diabetes_X_train, diabetes_y_train)"
        }, 
        {
            "execution_count": 47, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SystemML Statistics:\nTotal execution time:\t\t0.003 sec.\nNumber of executed Spark inst:\t1.\n\n\n"
                }
            ], 
            "source": "predictions = regr.predict(diabetes_X_test)"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}