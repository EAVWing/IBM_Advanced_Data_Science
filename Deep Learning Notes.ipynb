{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Deep Learning  Notes\n\n### Toy Perceptron", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "dp1 = {'partno': 100, 'maxtemp': 35, 'mintemp': 35, 'maxvibration': 12, 'asperity': 0.32}\ndp2 = {'partno': 101, 'maxtemp': 46, 'mintemp': 35, 'maxvibration': 21, 'asperity': 0.34}\ndp3 = {'partno': 130, 'maxtemp': 56, 'mintemp': 46, 'maxvibration': 3412, 'asperity': 12.42}\ndp4 = {'partno': 131, 'maxtemp': 58, 'mintemp': 48, 'maxvibration': 3542, 'asperity': 13.43}"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x1 = np.array([1] + [v for k, v in dp1.items()] [1:-1])\nx2 = np.array([1] + [v for k, v in dp2.items()] [1:-1])\nx3 = np.array([1] + [v for k, v in dp3.items()] [1:-1])\nx4 = np.array([1] + [v for k, v in dp4.items()] [1:-1])"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def sigmoid(x):\n    return 1/(1+np.exp(-x))"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "w_layer1 = np.random.rand(4)\n\ndef neuron(x):\n    return sigmoid(x.dot(w_layer1))"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 10, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.9999905776559888"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "neuron(x1)"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "w_layer1 = np.random.rand(4,4)\n\ndef layer1(x):\n    return sigmoid(x.dot(w_layer1))"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x = np.array([x1,x2,x3,x4])"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 13, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[   1,   35,   35,   12],\n       [   1,   46,   35,   21],\n       [   1,   56,   46, 3412],\n       [   1,   58,   48, 3542]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "x"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 14, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[1.        , 1.        , 0.99999979, 1.        ],\n       [1.        , 1.        , 1.        , 1.        ],\n       [1.        , 1.        , 1.        , 1.        ],\n       [1.        , 1.        , 1.        , 1.        ]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "layer1(x)"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "w_layer2 = np.random.rand(4,4)\n\ndef layer2(x):\n    return sigmoid(x.dot(w_layer2))"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 16, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[0.81406304, 0.87492758, 0.81747151, 0.96889498],\n       [0.81406305, 0.87492759, 0.81747152, 0.96889499],\n       [0.81406305, 0.87492759, 0.81747152, 0.96889499],\n       [0.81406305, 0.87492759, 0.81747152, 0.96889499]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "layer2(layer1(x))"
        }, 
        {
            "source": "###  Tensorflow ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190610135737-0000\nKERNEL_ID = d7426973-3646-4346-b646-cc1533503bfc\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "WARNING:tensorflow:From <ipython-input-1-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\nWARNING:tensorflow:From /opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\nWARNING:tensorflow:From /opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use urllib or similar directly.\nWARNING:tensorflow:From /opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nExtracting MNIST_data/train-images-idx3-ubyte.gz\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "WARNING:tensorflow:From /opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nWARNING:tensorflow:From /opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "WARNING:tensorflow:From /opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
                }
            ], 
            "source": "from tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import tensorflow as tf"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib.pyplot as plt"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
                }, 
                {
                    "execution_count": 10, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<matplotlib.image.AxesImage at 0x7ff416c1f390>"
                    }, 
                    "output_type": "execute_result"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    }, 
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ], 
            "source": "batch_xs, batch_ys = mnist.train.next_batch(1)\nX = batch_xs\nX = X.reshape([28, 28])\nplt.gray()\nprint(batch_ys) #one-hot encoded vector\nplt.imshow(X)"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "WARNING:tensorflow:From /opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
                }
            ], 
            "source": "x = tf.placeholder(tf.float32, [None, 784])\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\ny = tf.nn.softmax(tf.matmul(x, W) + b)"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y_ = tf.placeholder(tf.float32, [None, 10])"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "WARNING:tensorflow:From /opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
                }
            ], 
            "source": "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ *tf.log(y), reduction_indices = [1]))\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sess = tf.InteractiveSession()"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "tf.global_variables_initializer().run()"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "for _ in range(1000):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    sess.run(train_step, feed_dict = {x: batch_xs, y_:batch_ys})"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0.9172\n"
                }
            ], 
            "source": "print(sess.run(accuracy, feed_dict={x : mnist.test.images, y_: mnist.test.labels}))"
        }, 
        {
            "source": "### Keras Sequential Neural Networks", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Install tensorflow backend\n# pip install tensorflow\n\n# Optionally install other dependencies\n# pip install h5py graphviz pydot\n\n# Install keras\n# pip install keras"
        }, 
        {
            "source": "We can also import a loss function from the Keras loss module.  Same is true for optimizers.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# from keras.losses import mean_squared_error\n# model.compile(loss=mean_squared_error, optimizer=...)\n\n# instead of doing it as a string like\n# model.compile(loss = 'mean_squared_error', optimizer = ...)"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# from keras.optimizers import SGD\n# sgd = SGD(lr = 0.01,\n#          decay = 1e-6,\n#          momentum = 0.9)\n# model.compile(loss = mean_squared_error, optimizer=sgd)\n\n# instead of doing it as a string like:\n# model.compile(loss = ..., optimizer = 'sgd')\n# if you do it as a string it will use all the defaults"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# from keras.layers import Dense\n\n# Dense(units,             # Number of output neurons\n#      activation = None   # Default is none, change to sigmoid, relu etc\n#      use_bias = True     # leave this on\n#      kernel_initializer = 'glorot_uniform',\n#      bias_initializer = 'zeros')\n\n# from keras.layers import Dropout\n\n# Dropout(rate,    # Fraction of units to drop out on each forward pass\n#        seed=None)"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "from keras.datasets import mnist\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n"
                }
            ], 
            "source": "batch_size = 128\nnum_classes = 10\nepochs = 20\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model = Sequential()\nmodel.add(Dense(512, activation = 'relu', input_shape = (784,))) # only include the input shape for the first layer\nmodel.add(Dropout(rate = 0.2))\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(rate = 0.2))\nmodel.add(Dense(num_classes, activation = 'softmax'))"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_4 (Dense)              (None, 512)               401920    \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 669,706\nTrainable params: 669,706\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ], 
            "source": "model.summary()"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])  #sgd = stocastic gradient decent"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "WARNING:tensorflow:From /opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/20\n60000/60000 [==============================] - 6s 103us/step - loss: 1.2187 - acc: 0.6864 - val_loss: 0.5369 - val_acc: 0.8658\nEpoch 2/20\n60000/60000 [==============================] - 5s 90us/step - loss: 0.5301 - acc: 0.8504 - val_loss: 0.3749 - val_acc: 0.8957\nEpoch 3/20\n60000/60000 [==============================] - 5s 88us/step - loss: 0.4229 - acc: 0.8778 - val_loss: 0.3187 - val_acc: 0.9122\nEpoch 4/20\n60000/60000 [==============================] - 5s 87us/step - loss: 0.3741 - acc: 0.8909 - val_loss: 0.2895 - val_acc: 0.9187\nEpoch 5/20\n60000/60000 [==============================] - 5s 86us/step - loss: 0.3419 - acc: 0.8999 - val_loss: 0.2685 - val_acc: 0.9249\nEpoch 6/20\n60000/60000 [==============================] - 5s 85us/step - loss: 0.3190 - acc: 0.9074 - val_loss: 0.2520 - val_acc: 0.9296\nEpoch 7/20\n60000/60000 [==============================] - 5s 87us/step - loss: 0.2994 - acc: 0.9128 - val_loss: 0.2381 - val_acc: 0.9325\nEpoch 8/20\n60000/60000 [==============================] - 5s 91us/step - loss: 0.2820 - acc: 0.9184 - val_loss: 0.2255 - val_acc: 0.9361\nEpoch 9/20\n60000/60000 [==============================] - 6s 93us/step - loss: 0.2676 - acc: 0.9222 - val_loss: 0.2147 - val_acc: 0.9385\nEpoch 10/20\n60000/60000 [==============================] - 5s 90us/step - loss: 0.2543 - acc: 0.9258 - val_loss: 0.2050 - val_acc: 0.9397\nEpoch 11/20\n60000/60000 [==============================] - 5s 87us/step - loss: 0.2412 - acc: 0.9302 - val_loss: 0.1962 - val_acc: 0.9422\nEpoch 12/20\n60000/60000 [==============================] - 5s 85us/step - loss: 0.2319 - acc: 0.9330 - val_loss: 0.1873 - val_acc: 0.9446\nEpoch 13/20\n60000/60000 [==============================] - 5s 86us/step - loss: 0.2232 - acc: 0.9357 - val_loss: 0.1803 - val_acc: 0.9467\nEpoch 14/20\n60000/60000 [==============================] - 5s 86us/step - loss: 0.2119 - acc: 0.9387 - val_loss: 0.1738 - val_acc: 0.9482\nEpoch 15/20\n60000/60000 [==============================] - 5s 86us/step - loss: 0.2059 - acc: 0.9401 - val_loss: 0.1680 - val_acc: 0.9492\nEpoch 16/20\n60000/60000 [==============================] - 5s 85us/step - loss: 0.2005 - acc: 0.9412 - val_loss: 0.1621 - val_acc: 0.9515\nEpoch 17/20\n60000/60000 [==============================] - 5s 87us/step - loss: 0.1921 - acc: 0.9439 - val_loss: 0.1565 - val_acc: 0.9528\nEpoch 18/20\n60000/60000 [==============================] - 5s 86us/step - loss: 0.1848 - acc: 0.9463 - val_loss: 0.1523 - val_acc: 0.9547\nEpoch 19/20\n60000/60000 [==============================] - 5s 86us/step - loss: 0.1800 - acc: 0.9476 - val_loss: 0.1467 - val_acc: 0.9558\nEpoch 20/20\n60000/60000 [==============================] - 5s 86us/step - loss: 0.1741 - acc: 0.9490 - val_loss: 0.1434 - val_acc: 0.9565\n"
                }, 
                {
                    "execution_count": 12, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7fc6b7a4f908>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = (x_test, y_test))"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Test loss: 0.14342759463861585\nTest accuracy: 0.9565\n"
                }
            ], 
            "source": "score = model.evaluate(x_test, y_test, verbose = 0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])"
        }, 
        {
            "source": "### Keras Recurrent Neural Networks", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# from keras.layers.recurrent import LSTM\n\n# LSTM(units,\n#     activation = 'tanh',\n#     recurrent_activation = 'hard_sigmoid',\n#     recurrent_initializer = 'orthogonal',\n#     recurrent_regularizer = None,\n#     dropout = 0.0,\n#     recurrent_dropout = 0.0,\n#     return_sequences = False) # if you set this to true you'll get values for every time and the output will be a matrix instead of a vector"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# from keras.layers.embeddings import Embedding\n\n# Embedding(input_dim,        # Vocabulary size\n#          output_dim,        # Output vector length\n#          embeddings_initializer = 'uniform',\n#          mask_zero = False) # Mask zero values"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n17465344/17464789 [==============================] - 0s 0us/step\n"
                }
            ], 
            "source": "from keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding\nfrom keras.layers import LSTM\nfrom keras.datasets import imdb\n\nmax_features = 20000\nmaxlen = 80\n\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128))\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 25000 samples, validate on 25000 samples\nEpoch 1/15\n 5664/25000 [=====>........................] - ETA: 4:29 - loss: 0.6932 - acc: 0.5055"
                }, 
                {
                    "ename": "KeyboardInterrupt", 
                    "evalue": "", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-19-c75c33e8e8f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m/opt/ibm/conda/miniconda36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n", 
                        "\u001b[0;32m/opt/ibm/conda/miniconda36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/ibm/conda/miniconda36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/ibm/conda/miniconda36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/ibm/conda/miniconda36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, batch_size = 32, epochs = 15, validation_data = (x_test, y_test))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model.evaluate(x_test, y_test, batch_size = 32)"
        }, 
        {
            "source": "### Keras Functional API for non-Sequential models\n\nOften used when you already have atrained model and want new outputs", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from keras.layers import Input, Dense\nfrom keras.models import Model\n\nnum_classes = 10\ninputs = Input(shape = (784,))\n\nx = Dense(512, activation = 'relu')(inputs)\nx = Dense(512, activation = 'relu')(x)\n\npredictions = Dense(num_classes, activation = 'softmax')(x)"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model = Model(inputs=inputs, outputs=predictions)\nmodel.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\n#model.fil(...) same as before"
        }, 
        {
            "source": "### Saving and Loading Models (Serializing)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from keras.models import model_from_json\n\n# Save model as JSON and weights as HDF5\njson_string = model.to_json() # or model.to_yaml()\nmodel.save_weights('weights.h5')\n\n# Load from JSON and set weights\nmodel = model_from_json(json_string)\nmodel.load_weights('weights.h5')\n\n# to save/load the full model\nfrom keras.models import load_model\nmodel.save('full_model.h5')\nmodel = load_model('full_model.h5')"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}